<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>LSTM Madness/01/Data Prep &middot; </title>
        <meta name="description" content="Yahoo! Look at the previous posts about how to get data from Yahoo and use that to create a script to get the historical data from the XLF and each of its components. Don’t know the XLF components by heart? You can find them right here.
If that’s too much for you, you can just run python main.py in /get_yahoo_data of this repo. You’re going to have to run it twice, once for the components and once for just the XLF price series.">
        <meta name="HandheldFriendly" content="True">
        <meta name="MobileOptimized" content="320">
        <meta name="generator" content="Hugo 0.18.1" />
        <meta name="robots" content="index,follow">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <link rel="stylesheet" href="https://ventrisco.github.io/site/dist/styles.css">
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,400,600,700,300&subset=latin,cyrillic-ext,latin-ext,cyrillic">
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
        
    </head>
    <body>
        

        <div id="wrapper">
            <header class="site-header">
                <div class="container">
                    <div class="site-title-wrapper">
                        
                            <h1 class="site-title">
                                <a title="Ventris &amp; Co" href="https://ventrisco.github.io/site/">Ventris &amp; Co</a>
                            </h1>
                        
                        <a class="button-square" href="https://ventrisco.github.io/site/index.xml"><i class="fa fa-rss"></i></a>
                        
                        
                        
                            <a class="button-square button-social hint--top" data-hint="Github" title="Github" href="https://github.com/ventrisco">
                                <i class="fa fa-github-alt"></i>
                            </a>
                        
                        
                        
                        
                        
                            <a class="button-square button-social hint--top" data-hint="Email" title="Email" href="mailto:m@ventris.co">
                                <i class="fa fa-envelope"></i>
                            </a>
                        
                    </div>

                    <ul class="site-nav">
                        
                    </ul>
                </div>
            </header>

            <div id="container">


<div class="container">
    <article class="post-container" itemscope="" itemtype="http://schema.org/BlogPosting">
        <header class="post-header">
    <h1 class="post-title" itemprop="name headline">LSTM Madness/01/Data Prep</h1>
    
    <p class="post-date">
        <span>Published <time datetime="2017-03-06" itemprop="datePublished">Mon, Mar 6, 2017</time></span>
        <span>by</span>
        <span itemscope="" itemprop="author" itemtype="https://schema.org/Person">
            <span itemprop="name">
                <a href="" itemprop="url" rel="author"></a>
            </span>
        </span>
    </p>
</header>

        <div class="post-content clearfix" itemprop="articleBody">
    

    

<h1 id="yahoo">Yahoo!</h1>

<p>Look at the previous posts about how to get data from Yahoo and use that to create a script to get the historical data from the XLF and each of its components. Don’t know the XLF components by heart? You can find them right here.</p>

<p>If that’s too much for you, you can just run <code>python main.py</code> in <code>/get_yahoo_data</code> of this repo. You’re going to have to run it twice, once for the components and once for just the XLF price series. Save them to different buffers because we’re going to copy them to different tables.</p>

<h1 id="in-the-beginning">In the beginning</h1>

<p>So that we’re on the same page, let’s create a new user and database.</p>

<pre><code>CREATE USER ventris_admin WITH PASSWORD 'X4NAdu';
ALTER ROLE ventris_admin WITH SUPERUSER;
CREATE DATABASE ventris WITH OWNER ventris_admin;
</code></pre>

<p>Now you should be able to login into your database like so:</p>

<pre><code>psql -d ventris -U ventris_admin -h 127.0.0.1
</code></pre>

<p>If you followed the instructions above, you should have two files, one with just the XLF price data and the other with the price data for all of its components. Let’s create two tables to copy the data into.</p>

<pre><code>DROP TABLE IF EXISTS xlf_components_data;
CREATE TABLE xlf_components_data (
  ticker text
, dt date
, open numeric
, high numeric
, low numeric
, close numeric
, volume numeric
, adj_close numeric
);

COPY xlf_components_data FROM '&lt;YOUR FILEPATH HERE&gt;' WITH DELIMITER ',';

DROP TABLE IF EXISTS xlf_etf_data;
CREATE TABLE xlf_etf_data (
  ticker text
, dt date
, open numeric
, high numeric
, low numeric
, close numeric
, volume numeric
, adj_close numeric
);

COPY xlf_etf_data FROM '&lt;YOUR XLF FILEPATH HERE&gt;' WITH DELIMITER ',';
Calculate Returns
</code></pre>

<p>Now that we have our price data loaded let’s derive a table of returns for each of these tables. You calculate the return by taking today&rsquo;s close - yesterday&rsquo;s close and dividing the result by yesterday&rsquo;s close. Calculating the returns kills two birds with one stone. It normalizes our data and provides us with a table to help us calculate how much money we made.</p>

<pre><code>-- Create returns based on the days's close
DROP TABLE IF EXISTS xlf_components_returns;
CREATE TABLE xlf_components_returns AS
SELECT
  dt
, ticker
, CASE
    WHEN LAG(close, 1) OVER (PARTITION BY ticker ORDER BY dt) &gt; 0
      THEN (close - LAG(close, 1) OVER (PARTITION BY ticker ORDER BY dt)) / LAG(close, 1) OVER (PARTITION BY ticker ORDER BY dt)
    ELSE NULL END AS ret
FROM xlf_components_data;

-- Create returns of xlf
DROP TABLE IF EXISTS xlf_returns;
CREATE TABLE xlf_returns AS
SELECT
  dt
, ticker
, CASE
    WHEN LAG(close, 1) OVER (PARTITION BY ticker ORDER BY dt) &gt; 0
      THEN (close - LAG(close, 1) OVER (PARTITION BY ticker ORDER BY dt)) / LAG(close, 1) OVER (PARTITION BY ticker ORDER BY dt)
    ELSE NULL END AS ret
FROM xlf_etf_data;
</code></pre>

<p>This should be pretty straightforward. If Postgresql’s window functions are new to you, you should stop and read up on them. Window functions are indispensable for backtests and is really the most under appreciated feature of Postgresql.</p>

<p>The last thing we have to do is create a table with XLF’s next day’s returns. This will be the Y value for fitting our models and is just like our returns table except the returns are offset by one day. For example, our XLF returns table looks like this:</p>

<pre><code>dt     | ticker |           ret           
------------+--------+-------------------------
1998-12-22 | xlf    |                        
1998-12-23 | xlf    |  0.01474535247145115037
1998-12-24 | xlf    |  0.00660497782213908891
1998-12-28 | xlf    | -0.01312336068227701268
</code></pre>

<p>While our xlf_next_day_returns table looks like this:</p>

<pre><code>dt     | ticker |           ret           
------------+--------+-------------------------
1998-12-22 | xlf    |  0.01474535247145115037
1998-12-23 | xlf    |  0.00660497782213908891
1998-12-24 | xlf    | -0.01312336068227701268
1998-12-28 | xlf    |  0.01063829877772755555
</code></pre>

<p>We could create these returns when we do our SQL calls but I find that it’s cleaner to just create a table with those returns:</p>

<pre><code>DROP TABLE IF EXISTS xlf_next_day_returns;
CREATE TABLE xlf_next_day_returns AS
SELECT
  dt
, ticker
, CASE
    WHEN LEAD(close, 1) OVER (PARTITION BY ticker ORDER BY dt) &gt; 0
      THEN (LEAD(close, 1) OVER (PARTITION BY ticker ORDER BY dt) - close) / close
    ELSE NULL END AS ret
FROM xlf_etf_data;
</code></pre>

<p>Now that you can follow along at home, let’s build our first neural network!</p>

</div>

        <footer class="post-footer clearfix">
    

    <div class="share">
        
            <a class="icon-twitter" href="https://twitter.com/share?text=LSTM%20Madness%2f01%2fData%20Prep&url=https%3a%2f%2fventrisco.github.io%2fsite%2fblog%2flstm_madness_01%2f"
                onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                <i class="fa fa-twitter"></i>
                <span class="hidden">Twitter</span>
            </a>
        

        
            <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fventrisco.github.io%2fsite%2fblog%2flstm_madness_01%2f"
                onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                <i class="fa fa-facebook"></i>
                <span class="hidden">Facebook</span>
            </a>
        

        
            <a class="icon-google-plus" href="https://plus.google.com/share?url=https%3a%2f%2fventrisco.github.io%2fsite%2fblog%2flstm_madness_01%2f"
              onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
              <i class="fa fa-google-plus"></i>
                <span class="hidden">Google+</span>
            </a>
        
        
    </div>
</footer>

        
    <div class="comments">
        <div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'ventrisco';
    var disqus_identifier = 'https:\/\/ventrisco.github.io\/site\/blog\/lstm_madness_01\/';
    var disqus_title = 'LSTM Madness\/01\/Data Prep';
    var disqus_url = 'https:\/\/ventrisco.github.io\/site\/blog\/lstm_madness_01\/';

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </div>

    </article>
</div>

            </div>
        </div>

        <footer class="footer">
            <div class="container">
                <div class="site-title-wrapper">
                    <h1 class="site-title">
                        <a title="Ventris &amp; Co" href="https://ventrisco.github.io/site/">Ventris &amp; Co</a>
                    </h1>
                    <a class="button-square button-jump-top js-jump-top" href="#">
                        <i class="fa fa-angle-up"></i>
                    </a>
                </div>

                <p class="footer-copyright">
                    <span>&copy; 2017 / Powered by <a href="https://gohugo.io/">Hugo</a></span>
                </p>
                <p class="footer-copyright">
                    <span><a href="https://github.com/roryg/ghostwriter">Ghostwriter theme</a> By <a href="http://jollygoodthemes.com">JollyGoodThemes</a></span>
                    <span>/ <a href="https://github.com/jbub/ghostwriter">Ported</a> to Hugo By <a href="https://github.com/jbub">jbub</a></span>
                </p>
            </div>
        </footer>

        <script src="https://ventrisco.github.io/site/js/jquery-1.11.3.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/highlight.min.js"></script>
        <script src="https://ventrisco.github.io/site/js/jquery.fitvids.js"></script>
        <script src="https://ventrisco.github.io/site/js/scripts.js"></script>
    </body>
</html>

